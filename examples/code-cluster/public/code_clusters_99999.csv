id,Code_Block,Cluster
0,"train_data.describe()
",0
1,"df_test.tail()
",0
2,"test.tail()
",0
3,"train.describe()
",0
4,"train_df.info()
",0
5,"df_test.head()
",0
6,"train.info()
",0
7,"rfr1.fit(X1, y1)
",0
8,"train.corr()
",0
9,"print(finalPred1[:,])
",0
10,"xsubmission.head(10)
",0
11,"df_train.head()
",0
12,"y_train.head()
",0
13,"print(y1Pred[:,])
",0
14,"model.fit(X_train_f,y_train_f)
",0
15,"test_data.describe()
",0
16,"test_df.info()
",0
17,"df_train.info()
",0
18,"train_df.head(50)
",0
19,"test.head()
",0
20,"xtest.head(10)
",0
21,"test.describe()
",0
22,"Train_data.head()
",0
23,"gbr.fit(df_train_ohe,train_revenue)
",0
24,"xtrain.head(10)
",0
25,"df_out.tail()
",0
26,"rfr2.fit(X2, y2)
",0
27,"sub.sample(20)
",0
28,"train.keys()
",0
29,"Test_data.head()
",0
30,"train.sample(3)
",0
31,"output.tail(30)
",0
32,"print(finalPred2[:,])
",0
33,"y_pred.mean()
",0
34,"model.fit(X_train,y_train)
",0
35,"test.info()
",0
36,"train.tail()
",0
37,"df_test.info()
",0
38,"output.describe()
",0
39,"outputFile.sample(3)
",0
40,"train.head()
",0
41,"from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
",1
42,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
",1
43,"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import matplotlib.pyplot as plt
",1
44,"import pandas as pd
import datetime
import lightgbm as lgb
import numpy as np
from sklearn import preprocessing
",1
45,"import seaborn as sns
from sklearn.base import BaseEstimator
from xgboost import XGBClassifier, XGBRegressor
import hyperopt as hp
from hyperopt import STATUS_OK, Trials, fmin, hp, tpe
",1
46,"sub_df.to_csv(""submission.csv"", index=False, columns=[""ForecastId""] + TARGETS)
",2
47,"submission_df.to_csv(""submission.csv"", index=False, header=True)
",2
48,"from sklearn.model_selection import train_test_split
trainX , valX, trainY, valY = train_test_split(X, Y, random_state=1)
",2
49,"from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(handle_unknown='ignore')
",2
50,"from sklearn.model_selection import ShuffleSplit, cross_val_score
skfold = ShuffleSplit(random_state=7)
",2
51,"from sklearn.tree import DecisionTreeRegressor
lrModel1 = DecisionTreeRegressor(random_state = 27)
",2
52,"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
",2
53,"from sklearn import preprocessing
le = preprocessing.LabelEncoder()
",2
54,"train['Province_State'] = np.where(train['Province_State'].isnull(), train['Country_Region'], train['Province_State'])
test['Province_State'] = np.where(test['Province_State'].isnull(), test['Country_Region'], test['Province_State'])
",3
55,"pred_df['ConfirmedCases'] = (
    case_scaler.inverse_transform(pred_df['ConfirmedCases_scaled'].values.reshape(1,-1))[0])
pred_df['Fatalities'] = (
    fat_scaler.inverse_transform(pred_df['Fatalities_scaled'].values.reshape(1,-1))[0])
",3
56,"for date in dates:
    k = k-1
    i = i+1
    test.loc[(test['Country_Region']=='Italy')&(test['Date']==date),
            'ConfirmedCases_x']=last_amount.values[0] + i*(5000-(100*i))
    test.loc[(test['Country_Region']=='Italy')&(test['Date']==date),
             'Fatalities_x'] =  last_fat.values[0]+i*(800-(10*i))
",3
57,"k=30
i=0
for date in dates:
    k = k-1
    i = i+1
    test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']==date),'ConfirmedCases_x']= last_amount.values[0]
    test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']==date),'Fatalities_x']= last_fat.values[0] + i
",3
58,"last_amount = test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']=='2020-03-31'),'ConfirmedCases_x']
last_fat = test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']=='2020-03-31'),'Fatalities_x']
",3
59,"sns.lineplot(data=xtrain, x=""Date"", y=""ConfirmedCases"", hue=""Region"")
plt.show()
",4
60,"sns.lineplot(data=xtrain, x=""Date"", y=""Fatalities"", hue=""Region"")
plt.show()
",4
61,"train_df.drop(""Date"", inplace = True, axis = 1)
test_df.drop(""Date"", inplace = True, axis = 1)
",4
62,"ranked = country.sort_values(by = 'ConfirmedCases', ascending = False)[:15]
ranked
",4
63,"df.drop_duplicates(subset = ['Date', 'Province_State'], keep = 'last', inplace = True)
",4
64,"X_train, X_valid, y_train, y_valid = train_test_split(encod_train_data, y_conf, train_size=0.8,
                                                      test_size=0.2, random_state=0)
",4
65,"X_train_f, X_valid_f, y_train_f, y_valid_f = train_test_split(encod_train_data, y_fatal, train_size=0.8,
                                                      test_size=0.2, random_state=0)
",4
66,"from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 4, metric = 'braycurtis', p = 1)
classifier.fit(X1, y1)
",4
67,"from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 4, metric = 'braycurtis', p = 1)
classifier.fit(X2, y2)
",4
68,"n_folds = 5
cv = KFold(n_splits = 5, shuffle=True, random_state=42).get_n_splits(X_train.values)
",4
69,"model = CatBoostRegressor(iterations=4000,
                          depth=9,
                          learning_rate=0.5,
                          loss_function='RMSE')
",4
70,"train[train['Date']==date]
",5
71,"train[train['Province_State'] == 'Diamond Princess']
",5
72,"df_train.shape, df_test.shape
",5
73,"df_worldinfor[df_worldinfor['Country'] == 'Vietnam']
",5
74,"last_fat.values[0]
",5
75,"test[test['Country_Region']=='Italy']
",5
76,"train_df = train_df[[""Province_State"", ""Country_Region"", ""Date"", ""ConfirmedCases"", ""Fatalities""]]
train_df
",5
77,"X_Train.Country = le.fit_transform(X_Train.Country)
X_Train['State'] = le.fit_transform(X_Train['State'])
X_Train.head()
",6
78,"X_Test.Country = le.fit_transform(X_Test.Country)
X_Test['State'] = le.fit_transform(X_Test['State'])
X_Test.head()
",6
79,"models = []
models.append(('lr',lr))
models.append(('rfr',rfr))
models.append(('gbr',gbr))
models.append(('xgbr',xgbr))
",6
80,"le = preprocessing.LabelEncoder()
train['province_encoder'] = le.fit_transform(train['Province_State'])
test['province_encoder'] = le.transform(test['Province_State'])
",6
81,"test_data['Date'] = pd.to_datetime(test_data['Date'])
test_data.Date.max()-test_data.Date.min()
",6
82,"df_test['ConfirmedCases'] = model1.predict(df_test.drop(['Date', 'ForecastId'], axis=1))
df_test['Fatalities'] = model2.predict(df_test.drop(['Date', 'ForecastId', 'ConfirmedCases'], axis=1))
",6
83,"train['day_dist'] = train['Date']-train['Date'].min()
",7
84,"cat_cols = train.dtypes[train.dtypes=='object'].keys()
cat_cols
",7
85,"val = train[(train['Date']>='2020-03-12')&(train['Id'].isnull()==False)]
",7
86,"Y = train.iloc[:,-2:]
print(Y.shape)
Y.sample(3)
",7
87,"y1Train = trainY.iloc[:,0]
print(y1Train.shape)
y1Train.sample(3)
",7
88,"X = train.iloc[:,:-2]
print(X.shape)
X.sample(3)
",7
89,"train['day_dist'] = train['day_dist'].dt.days
",7
90,"last_amount = test.loc[(test['Country_Region']=='Italy')&(test['Date']=='2020-03-31'),'ConfirmedCases_x']
",7
91,"last_fat = test.loc[(test['Country_Region']=='Italy')&(test['Date']=='2020-03-31'),'Fatalities_x']
",7
92,"train[train['Province_State'].isnull()]['Country_Region'].unique()
",7
93,"train[train['Province_State'].notnull()]['Country_Region'].unique()
",7
94,"group = df.groupby(['Province_State', 'Country_Region'])['Date'].count().reset_index()
group
",7
95,"dfg = df.groupby([df.Country_Region, df.Province_State])
dfg.head()
",7
96,"df['Province_State'] = np.where((df['Country_Region'] == 'Georgia') & (df['Province_State'] == 'Georgia'),
                                'Country Georgia', df['Province_State'])
",7
97,"statevalue = xtrain.groupby('Province_State').max().ConfirmedCases
",7
98,"df[""Date""].min(), df[""Date""].max()
",7
99,"def func(x, b, n):
    return x * (b ** (1/n))
",7
100,"submission = pd.read_csv(""../input/covid19-global-forecasting-week-2/submission.csv"")
submission
",8
101,"countries = set(train_df[""Country_Region""])
countries
",8
102,"final_preds_conf = model.predict(encod_test_data)
",8
103,"submission.to_csv(""submission.csv"",index=False)
",8
104,"y_n_1 = rfr1.predict(test_1)
",8
105,"df_out.to_csv('submission.csv', index=False)
",8
106,"train_data.describe(include=['O'])
",8
107,"sub.to_csv(""submission.csv"",index=False)
",8
108,"outputFile.to_csv(""submission.csv"", index=False)
",8
109,"train_sub = pd.read_csv(""../input/covid19-global-forecasting-week-2/train.csv"")
",8
110,"y_n_2 = rfr2.predict(test_2)
",8
111,"test_data.describe(include=['O'])
",8
112,"gridsearch = gridsearch.fit(x,y)
",8
113,"df_results.to_csv('submission.csv', index=False)
",8
114,"train.describe(include=['object'])
",8
115,"final_preds_fatal = model.predict(encod_test_data)
",8
116,"submission.to_csv('submission.csv', index=False)
",8
117,"train_revenue = df_train.pop('revenue')
",8
118,"sub.to_csv('submission.csv',index=False)
",8
119,"le = preprocessing.LabelEncoder()
",8
120,"df = train.append(test)
",8
121,"drop_cols = ['Id','ForecastId', 'ConfirmedCases','Date', 'Fatalities',
             'day_dist', 'Province_State', 'Country_Region'] #,'day_dist','shift_22_ft','shift_23_ft','shift_24_ft','shift_25_ft','shift_26_ft']
",8
122,"dates = dates[dates>'2020-03-31']
",8
123,"from sklearn.linear_model import (
    ElasticNet,
    ElasticNetCV,
    Lasso,
    LassoCV,
    LinearRegression,
    LogisticRegression,
    Ridge,
)
from sklearn.ensemble import (
    AdaBoostClassifier,
    GradientBoostingClassifier,
    GradientBoostingRegressor,
    RandomForestClassifier,
    RandomForestRegressor,
    VotingClassifier,
)
from sklearn.model_selection import (
    GridSearchCV,
    KFold,
    RandomizedSearchCV,
    cross_val_score,
    train_test_split,
)
",9
124,"import matplotlib.pyplot as plt
from sklearn import model_selection
import numpy as np
",9
125,"xsubmission.to_csv(""submission.csv"", index=False)
print(""Submission file create sucessfully"")
",10
126,"yhat_val_cc = model_cc.predict(X_val_cc)
print(yhat_val_cc)
",10
127,"yhat_val_ft = model_cc.predict(X_val_ft)
print(yhat_val_ft)
",10
128,"preds = model.predict(X_valid_f)
print('MAE:', mean_absolute_error(y_valid_f, preds))
",10
129,"preds = model.predict(X_valid_f)
print('MSE:', mean_squared_error(y_valid_f, preds))
",10
130,"preds = model.predict(X_valid)
print('MSE:', mean_squared_error(y_valid, preds))
",10
131,"preds = model.predict(X_valid)
print('MAE:', mean_absolute_error(y_valid, preds))
",10
132,"df_out['ConfirmedCases'] = df_out['ConfirmedCases'].round().astype(int)
df_out['Fatalities'] = df_out['Fatalities'].round().astype(int)
",11
133,"train_levels = Train_data.loc[(Train_data['City'].notnull())]
City_counts = train_levels['City'].value_counts().sort_index().to_frame()
City_counts
",11
134,"train_levels = Train_data.loc[(Train_data['Type'].notnull())]
label_counts = train_levels['Type'].value_counts().sort_index().to_frame()
label_counts
",11
135,"data = pd.read_csv('../input/covid19-global-forecasting-week-2/train.csv')
test_data = pd.read_csv('../input/covid19-global-forecasting-week-2/test.csv')
submission = pd.read_csv('../input/covid19-global-forecasting-week-2/submission.csv')
print(data.shape)
print(test_data.shape)
print(submission.shape)
",11
136,"df_xtrain = xtrain.groupby(['Country_Region'])[['ConfirmedCases', 'Fatalities']].max()
print(df_xtrain.sort_values(by=['ConfirmedCases','Fatalities'],ascending=False).head(10))
",11
137,"import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from skmultilearn.problem_transform import BinaryRelevance
from sklearn.naive_bayes import GaussianNB
",12
138,"print(""Read in libraries"")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima_model import ARIMA
from random import random
",12
139,"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import seaborn as sns
from datetime import datetime
",12
140,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings(""ignore"")
",12
141,"sub['Fatalities'].describe()
",13
142,"xtrain['Date'].value_counts()
",13
143,"train['City Group'].value_counts()
",13
144,"train_df.Province_State.value_counts()
",13
145,"train['City'].value_counts()
",13
146,"train['Type'].value_counts()
",13
147,"sub['ConfirmedCases'].describe()
",13
148,"print(x.shape,y.shape)
",13
149,"print(test.shape)
test.sample(3)
",13
150,"train.isnull().sum()
",13
151,"set(train_df[""Country_Region""]) == set(test_df[""Country_Region""])
",13
152,"test.isnull().sum()
",13
153,"train_data.isna().sum()
",13
154,"test_data.isna().sum()
",13
155,"xtrain.isnull().sum()
",13
156,"print(trainX.shape)
trainX.sample(3)
",13
157,"def RMSLE(pred,actual):
        return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))
",14
158,"def root_mean_squared_log_error(y_true, y_pred):
    return K.sqrt(K.mean(K.square(K.log(y_pred + 1) - K.log(y_true + 1))))
",14
159,"import plotly.express as px
import plotly.graph_objs as go
from plotly.subplots import make_subplots
import plotly
plotly.offline.init_notebook_mode() # For not show up chart error
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
from tqdm import tqdm
def RMSLE(pred,actual):
    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))
",14
160,"def get_score(n_estimators):
    model = GradientBoostingRegressor(n_estimators=n_estimators)
    scores = cross_val_score(model, X_train, y_train, cv=5)
    return scores.mean()
",15
161,"def rmse_score(n_estimators):
    rmse = np.sqrt(-cross_val_score(GradientBoostingRegressor(n_estimators=n_estimators), X_train, y_train, scoring=""neg_mean_squared_error"", cv = 5))
    return(rmse)
",15
162,"xsubmission.Fatalities = round(pd.DataFrame(y_n_2))
",16
163,"df_submit.to_csv('submit.csv',index=False)
df_submit.head()
",16
164,"test = pd.read_csv('../input/covid19-global-forecasting-week-2/test.csv')
test.info()
",16
165,"dftest = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/test.csv"")
dftest.head(40)
",16
166,"train = pd.read_csv('../input/covid19-global-forecasting-week-2/train.csv')
train.info()
",16
167,"data = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/train.csv.zip')
data.head()
",16
168,"xsubmission.ConfirmedCases = round(pd.DataFrame(y_n_1))
",16
169,"train = train.append(test[test['Date']>'2020-03-31'])
",16
170,"y1_Train = df_train.iloc[:, -2]
y1_Train.head()
",16
171,"pdq_results = comb_p_d_q([0,1,2],[0,1,2],[0,1,2])
pdq_results
",16
172,"y2_Train = df_train.iloc[:, -1]
y2_Train.head()
",16
173,"y2Val = valY.iloc[:,1]
y2Val.sample(3)
",16
174,"y1Val = valY.iloc[:,0]
y1Val.sample(3)
",16
175,"df_train = df_train[['Date','Province_State','Country_Region','ConfirmedCases','Fatalities']]
df_train.head()
",16
176,"y2Train = trainY.iloc[:,1]
y2Train.sample(3)
",16
177,"df_submit = pd.DataFrame({'Id': df_test_index, 'Prediction': test_revenue})
",16
178,"import numpy as np
import pandas as pd
df = pd.read_csv(""../input/covid19-global-forecasting-week-2/train.csv"")
df.shape
",16
179,"import matplotlib.pyplot as plt
import seaborn as sns
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import RepeatVector
from keras.layers import TimeDistributed
from keras.models import Sequential
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_log_error
from sklearn.preprocessing import MinMaxScaler
",17
180,"import plotly.graph_objects as go
import matplotlib.pyplot as plt
from tqdm import tqdm
import time
from datetime import datetime
from pathlib import Path
from sklearn import preprocessing
import keras.backend as K
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, GRU
from keras.callbacks import EarlyStopping
from sklearn.preprocessing import StandardScaler, MinMaxScaler
",17
181,"import numpy as np
import pandas as pd
",18
182,"from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import GridSearchCV
",18
183,"from xgboost import XGBRegressor
import lightgbm as lgb
",18
184,"from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error
",18
185,"import pandas as pd
import numpy as np
BIG_NUMBER = 1000000
",18
186,"encodering = LabelEncoder()
encod_train_data = train_data.copy()
encod_test_data = test_data.copy()
for col in categorical_cols:
    encod_train_data[col] = encodering.fit_transform(train_data[col])
    encod_test_data[col] = encodering.fit_transform(test_data[col])
",19
187,"pin = [first_input]
pout = [first_pred]
for i in range(42):
    p = final_regressor.predict(pin[i])
    pout.append(p)
    t= np.insert(pin[i],n_in,pout[i],axis=1)[:,1:,:]
    pin.append(t)
",19
188,"loc_group = [""Province_State"", ""Country_Region""]
def preprocess(df):
    df[""Date""] = df[""Date""].astype(""datetime64[ms]"")
    for col in loc_group:
        df[col].fillna(""none"", inplace=True)
    return df
df = preprocess(df)
sub_df = preprocess(pd.read_csv(""../input/covid19-global-forecasting-week-2/test.csv""))
df.head()
",19
189,"from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
def FunLabelEncoder(df):
    for c in df.columns:
        if df.dtypes[c] == object:
            le.fit(df[c].astype(str))
            df[c] = le.transform(df[c].astype(str))
    return df
",19
190,"MIN_TEST_DATE = xtest.Date.min()
xtrain = xtrain.loc[xtrain.Date < MIN_TEST_DATE, :]
",20
191,"results = test[['ForecastId', 'ConfirmedCases', 'Fatalities']]
results.to_csv('submission.csv', index = False)
",20
192,"sub = pred_df[['ConfirmedCases','Fatalities']]
sub['ForecastId'] = test_data['ForecastId']
",20
193,"df_out['ConfirmedCases'] = (1/2)*(df_out['ConfirmedCases'] + df_out2['ConfirmedCases'])
df_out['Fatalities'] = (1/2)*(df_out['Fatalities'] + df_out2['Fatalities'])
",20
194,"def mape (y_true, y_pred):
    return np.mean(np.abs(y_pred -y_true)*100/(y_true+1))
",21
195,"def sigmoid(x, a, b, c):
    return a*np.exp(c*(x-b))/(np.exp(c*(x-b))+1)
",21
196,"def split_train_val(df, val_ratio):
    val_len = int(len(df) * val_ratio)
    train_set =  df[:-val_len]
    val_set = df[-val_len:]
    return train_set, val_set
",21
197,"def comb_p_d_q(pVals,dVals,qVals):
    return [(p,d,q) for p in pVals for d in dVals for q in qVals]
",21
198,"plt.figure(figsize=(15,6))
sns.lineplot(x=xtrain.Date,y=xtrain.ConfirmedCases,markers=True,style=True)
plt.xticks(rotation = 'vertical')
",22
199,"plt.figure(figsize=(15,6))
sns.lineplot(x=xtrain.Date,y=xtrain.Fatalities,markers=True,style=True)
plt.xticks(rotation = 'vertical')
",22
200,"top_states = statevalue.sort_values(ascending = False).head(10)
sns.barplot(x=top_states.index, y=top_states.values)
plt.xticks(rotation = 'vertical')
",22
201,"xtrain.Date = pd.to_datetime(xtrain.Date, infer_datetime_format=True)
xtest.Date = pd.to_datetime(xtest.Date, infer_datetime_format=True)
",23
202,"df_train['Date'] = pd.to_datetime(df_train['Date'], infer_datetime_format=True)
df_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)
",23
203,"test.loc[test['ConfirmedCases_x'].isnull()==True, 'ConfirmedCases_x'] =test.loc[test['ConfirmedCases_x'].isnull()==True, 'ConfirmedCases_y']
",23
204,"test.loc[test['Fatalities_x'].isnull()==True, 'Fatalities_x'] = test.loc[test['Fatalities_x'].isnull()==True, 'Fatalities_y']
",23
205,"X1 = xtrain.drop([""ConfirmedCases"", ""Fatalities""], axis=1)
X2 = xtrain.drop([""ConfirmedCases"", ""Fatalities""], axis=1)
y1 = xtrain[""ConfirmedCases""]
y2 = xtrain[""Fatalities""]
",23
206,"train_data = raw_train_data
train_data['Date'] = pd.to_datetime(train_data['Date'])
train_data['Province_State'] = train_data['Province_State'].fillna('None')
",23
207,"df_train = df_train.loc[:,~df_train.columns.duplicated()]
df_test = df_test.loc[:,~df_test.columns.duplicated()]
print (df_test.shape)
",23
208,"raw_train_data['Date'] = pd.to_datetime(raw_train_data['Date'])
test_check = raw_train_data[raw_train_data['Date']>'2020-03-18']
model_check = pred_df[pred_df['Date']<=test_check['Date'].max()]
",23
209,"submission = pd.DataFrame()
submission['ForecastId'] = test_df['ForecastId']
submission['ConfirmedCases'] = test_df['cc_cases']
submission['Fatalities'] = test_df['ft_cases']
",23
210,"y_pred1 = classifier.predict(X1)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y1, y_pred1)
from sklearn.metrics import accuracy_score
print( 'Accuracy Score confirmed cases :',accuracy_score(y1,y_pred1)*100)
",24
211,"y_pred2 = classifier.predict(X2)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y2, y_pred2)
from sklearn.metrics import accuracy_score
print( 'Accuracy Score confirmed cases :',accuracy_score(y2,y_pred2)*100)
",24
212,"from sklearn import linear_model
from sklearn.ensemble import RandomForestRegressor
cls = RandomForestRegressor(n_estimators=170)
cls.fit(xTrain, yTrain)
pred = cls.predict(xTest)
pred = numpy.exp(pred)
closs = cls.score(xTrain, yTrain)
closs
",24
213,"from sklearn.metrics import mean_squared_error
mse = mean_squared_error(train_revenue_predict,train_revenue)
rmse = np.sqrt(mse)
print(rmse)
",24
214,"italy = df_train[df_train['Country_Region'] == 'Italy']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'Fatalities' , data = italy,color='orange')
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Fatalities',size=15)
plt.title('Fatalities in Italy per Date',size=20)
plt.show()
",25
215,"usa = df_train[df_train['Country_Region'] == 'US']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'ConfirmedCases' , data = usa,color='g')
plt.xticks(rotation = 90,size=13)
plt.xlabel('Date',size=15)
plt.ylabel('Confirmed Cases',size=15)
plt.title('Confirmed Cases in US per Date',size=20)
plt.show()
",25
216,"plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'Fatalities' , data = usa,color='purple')
plt.title('Fatalities in US per Date',size=20)
plt.xticks(rotation = 90,size=13)
plt.xlabel('Date',size=15)
plt.ylabel('Fatalities',size=15)
plt.show()
",25
217,"plt.figure(figsize=(20,10))
sns.barplot(x='Province_State',y='ConfirmedCases',data=usa,ci=None)
plt.xticks(rotation = 90,size=13)
plt.xlabel('Province_State',size=15)
plt.ylabel('Confirmed Cases',size=15)
plt.title('Confirmed Cases in US Province_State ',size=20)
plt.show()
",25
218,"china  = df_train[df_train['Country_Region'] == 'China']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'ConfirmedCases' , data = china,color='aqua')
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Confirmed Cases',size=15)
sns.set_context('paper')
plt.title('Confirmed Cases in China per Date',size=20)
plt.show()
",25
219,"china  = df_train[df_train['Country_Region'] == 'China']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'Fatalities' , data = china,color='grey')
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Fatalities',size=15)
sns.set_context('paper')
plt.title('Fatalities in China per Date',size=20)
plt.show()
",25
220,"italy = df_train[df_train['Country_Region'] == 'Italy']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'ConfirmedCases' , data = italy)
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Confirmed Cases',size=15)
plt.title('Confirmed Cases per date in Italy',size=20)
plt.show()
",25
221,"plt.figure(figsize=(20,10))
sns.barplot(x='Province_State',y='ConfirmedCases',data=china)
plt.xticks(rotation = 90,size=13)
plt.title('Confirmed Cases in China Province_State',size=20)
plt.ylabel('Confirmed Cases',size=15)
plt.xlabel('Province_State',size=15)
plt.show()
",25
222,"X_train_cc = train_X_cc.to_numpy()
X_val_cc = val_X_cc.to_numpy()
X_train_ft = train_X_ft.to_numpy()
X_val_ft = val_X_ft.to_numpy()
y_train_cc = train_y_cc.to_numpy()
y_val_cc = val_y_cc.to_numpy()
y_train_ft = train_y_ft.to_numpy()
y_val_ft = val_y_ft.to_numpy()
",25
223,"global_cases = train_data.groupby(['Date'])[['ConfirmedCases','Fatalities']].sum()
fig,ax = plt.subplots(figsize=(8,5))
_=ax.plot(global_cases['ConfirmedCases'],label='Cases',c='k')
_=ax.plot(global_cases['Fatalities'],label='Deaths',c='r')
_=ax.xaxis.set_tick_params(rotation=15)
_=sns.despine()
_=ax.legend(loc=0)
_=ax.set(title=('Global cumulative cases and deaths'))
",25
224,"for col in TARGETS:
    test_df[col] = np.expm1(test_df[col])
    test_df[""pred_{}"".format(col)] = np.expm1(test_df[""pred_{}"".format(col)])
",26
225,"for col in TARGETS:
    df[""prev_{}"".format(col)] = df.groupby(loc_group)[col].shift()
",26
226,"for cat_col in ['place']:
    #train[cat_col].fillna('no_value', inplace = True) #train[cat_col].value_counts().idxmax()
    le = preprocessing.LabelEncoder()
    le.fit(train[cat_col])
    train[cat_col]=le.transform(train[cat_col])
",26
227,"for row in dftrain.itertuples():
    train(row.Country_Region, row.Province_State, row.GrowthRate)
",26
228,"TARGETS = [""ConfirmedCases"", ""Fatalities""]
for col in TARGETS:
    df[col] = np.log1p(df[col])
",26
229,"for cat_col in cat_cols:
    train[cat_col].fillna('no_value', inplace = True)
",26
230,"print(trainX.info())
",27
231,"print(train.info())
",27
232,"print(dfsubmission.head(60))
",27
233,"print(len(test))
",27
234,"categorical_cols = [cname for cname in train_data.columns if
                    train_data[cname].dtype == ""object""]
",28
235,"sub.loc[sub['Fatalities']<0, 'Fatalities']=0
",28
236,"sub.loc[sub['ConfirmedCases']<0,'ConfirmedCases']=0
",28
237,"train['place'] = train['Province_State']+'_'+train['Country_Region']
",28
238,"test.iloc[:,1:].sample(3)
",28
239,"pred_df[pred_df['Date']=='2020-04-30'].sum()
",28
240,"train.iloc[:,:-2].sample(3)
",28
241,"trainX.iloc[:,1:].sample(3)
",28
242,"test.loc[(test['Country_Region']=='Italy')] #&(test['Date']==date),'ConfirmedCases_x'
",28
243,"df_train.loc[df_train.Country == 'Afghanistan', :]
",28
244,"test[(test['Country_Region']=='China')&(test['Province_State']=='Zhejiang')]
",28
245,"X_scaler_cc = MinMaxScaler()
X_train_cc = X_scaler_cc.fit_transform(train_X_cc)
X_val_cc =  X_scaler_cc.transform(val_X_cc) # intput/output 2D array-like
y_scaler_cc = MinMaxScaler()
y_train_cc = y_scaler_cc.fit_transform(train_y_cc)
y_val_cc = y_scaler_cc.transform(val_y_cc) # array-like
",29
246,"X_scaler_ft = MinMaxScaler()
X_train_ft = X_scaler_ft.fit_transform(train_X_ft)
X_val_ft =  X_scaler_ft.transform(val_X_ft) # intput/output 2D array-like
y_scaler_ft = MinMaxScaler()
y_train_ft = y_scaler_ft.fit_transform(train_y_ft)
y_val_ft = y_scaler_ft.transform(val_y_ft) # array-like
",29
247,"from sklearn.linear_model import Ridge
reg_CC = Ridge(alpha=1.0)
reg_Fat = Ridge(alpha=1.0)
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)
print (score_CC.mean(), score_Fat.mean())
",29
248,"from sklearn.linear_model import ElasticNet
reg_CC = ElasticNet(random_state=0)
reg_Fat = ElasticNet(random_state=0)
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)
print (score_CC.mean(), score_Fat.mean())
",29
249,"test_fixed_cols = ['ForecastId', 'Province_State', 'Country_Region', 'Date']
fixed_cols = ['Id', 'province', 'country', 'date']
output_cols = ['cc_cases', 'ft_cases']
input_cols = list(set(train_df.columns.to_list()) - set(fixed_cols) - set(output_cols))
print('output columns are ', output_cols)
print('input columns are ', input_cols)
X = train_df[input_cols]
y = train_df[output_cols]
",29
250,"from sklearn import linear_model
reg_CC = linear_model.Lasso(alpha=0.1)
reg_Fat = linear_model.Lasso(alpha=0.1)
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)
print (score_CC.mean(), score_Fat.mean())
",29
251,"from sklearn import svm
reg_CC = svm.SVC()
reg_Fat = svm.SVC()
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)
print (score_CC.mean(), score_Fat.mean())
",29
252,"from sklearn.linear_model import LinearRegression
reg_CC = LinearRegression()
reg_Fat = LinearRegression()
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)
print (score_CC.mean(), score_Fat.mean())
",29
253,"def build_regressor(optimizer,lstm_nodes):
    # define model
    model = Sequential()
    model.add(LSTM(lstm_nodes, activation='relu', input_shape=(n_in,2)))
    model.add(Dense(2, activation='relu'))
    model.compile(optimizer=optimizer, loss='mean_squared_logarithmic_error')
    return model
",29
254,"from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
clf_bgr_CC = BaggingRegressor(base_estimator = DecisionTreeRegressor())
clf_bgr_Fat = BaggingRegressor(base_estimator = DecisionTreeRegressor())
rmsle_bgr_CC = test_model(clf_bgr_CC, ""CC"")
rmsle_bgr_Fat = test_model(clf_bgr_Fat, ""Fat"")
print (rmsle_bgr_CC, rmsle_bgr_Fat)
",29
255,"def GRU_model(n_1, input_dim, output_dim):
    model = Sequential()
    model.add(GRU(n_1,input_shape=(1, input_dim), activation='relu'))
    model.add(Dropout(0.1))
    model.add(Dense(output_dim, activation='relu'))
    model.compile(loss=root_mean_squared_log_error, optimizer='adam')
    print(model.summary())
    return model
",29
256,"lr = LinearRegression(n_jobs=-1)
rfr = RandomForestRegressor(random_state=96, n_jobs=-1)
gbr = GradientBoostingRegressor(random_state=96)
xgbr = XGBRegressor()
",29
257,"df_train_ohe = ohe.fit_transform(df_train)
df_train_ohe = df_train_ohe.todense()
",30
258,"df_test_ohe = ohe.transform(df_test)
df_test_ohe = df_test_ohe.toarray()
",30
259,"pred = cls.predict(xTest)
pred = numpy.exp(pred)
pred
",30
260,"train_df = pd.read_csv(""../input/covid19-global-forecasting-week-2/train.csv"")
test_df = pd.read_csv(""../input/covid19-global-forecasting-week-2/test.csv"")
",30
261,"train_data.fillna('-', inplace=True)
test_data.fillna('-',inplace=True)
",30
262,"train_revenue_predict = gbr.predict(df_train_ohe)
test_revenue = gbr.predict(df_test_ohe)
",30
263,"xtrain.fillna("""", inplace=True)
xtest.fillna("""", inplace=True)
",30
264,"raw_train_data = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')
test_data = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')
",30
265,"pred = cls.predict(xTest)
pred = numpy.exp(pred)
",30
266,"train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')
test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')
",30
267,"test_1 = xtest.copy()
test_2 = xtest.copy()
",30
268,"PATH_WEEK2='/kaggle/input/covid19-global-forecasting-week-2'
df_train = pd.read_csv(f'{PATH_WEEK2}/train.csv')
df_test = pd.read_csv(f'{PATH_WEEK2}/test.csv')
",30
269,"x_list = [X_train, X_valid]
y_list = [y_train, y_valid]
scoring = list(map(lambda x,y: round(model.score(x,y)*100, 2), x_list, y_list))
scoring
",31
270,"x_list_f = [X_train_f, X_valid_f]
y_list_f = [y_train_f, y_valid_f]
scoring = list(map(lambda x,y: round(model.score(x,y)*100, 2), x_list_f, y_list_f))
scoring
",31
271,"train = pd.read_csv(""../input/covid19-global-forecasting-week-2/train.csv"")
test = pd.read_csv(""../input/covid19-global-forecasting-week-2/test.csv"")
sub = pd.read_csv(""../input/covid19-global-forecasting-week-2/submission.csv"")
",31
272,"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')
df_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')
df_submit = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/submission.csv')
",31
273,"train_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv', na_filter=False)
test_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv', na_filter=False)
submission_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/submission.csv')
",31
274,"df_train.drop(objList, axis=1, inplace=True)
df_test.drop(objList, axis=1, inplace=True)
print (df_train.shape)
",31
275,"objList = df_train.select_dtypes(include = ""object"").columns
df_train = one_hot(df_train, objList)
df_test = one_hot(df_test, objList)
print (df_train.shape)
",31
276,"train_df = pd.read_csv(Path('/kaggle/working/', 'train_df.csv'), index_col = 0, parse_dates = ['date'])
train_df[train_df['country'] == 'Italy'].tail()
",31
277,"xtrain.drop(['Country_Region','Province_State'],axis=1,inplace=True)
xtest.drop(['Country_Region','Province_State'],axis=1,inplace=True)
",31
278,"read_test = {
    ""Id"":ID,
    ""Prediction"":pred
}
read_ = pd.DataFrame(read_test)
read_.to_csv(""sample_submission.csv"",index=False)
",31
279,"test.head()
test=test.drop(['City','Open Date','City Group'], axis=1)
",31
280,"xtrain = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/train.csv"")
xtest = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/test.csv"")
xsubmission = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/submission.csv"")
print(xtrain.shape)
print(xtest.shape)
",31
281,"X_train = train.drop(['City','Open Date','revenue','Id','City Group'], axis=1)
X_test    = test.drop(['City','Open Date','Id','City Group'], axis=1)
X_train.head()
",31
282,"reg_CC.fit(X_train, Y_train_CC)
Y_pred_CC = reg_CC.predict(X_test)
reg_Fat.fit(X_train, Y_train_Fat)
Y_pred_Fat = reg_Fat.predict(X_test)
",31
283,"plt.figure(figsize=(8,5))
plt.plot(history_cc.history['loss'])
plt.plot(history_cc.history['val_loss'])
plt.title('CC Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
",32
284,"plt.figure(figsize=(8,5))
plt.plot(history_ft.history['loss'])
plt.plot(history_ft.history['val_loss'])
plt.title('FT Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
",32
285,"rfr1 = RandomForestRegressor(
    max_features=3,
    min_samples_leaf=26,
    min_samples_split=31,
    n_estimators=200,
    random_state=96,
    n_jobs=-1,
)
",32
286,"rfr2 = RandomForestRegressor(
    max_features=3,
    min_samples_leaf=17,
    min_samples_split=17,
    n_estimators=100,
    random_state=96,
    n_jobs=-1,
)
",32
287,"from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
train_df.Country_Region = le.fit_transform(train_df.Country_Region)
train_df['Province_State'] = le.fit_transform(train_df['Province_State'])
test_df.Country_Region = le.fit_transform(test_df.Country_Region)
test_df['Province_State'] = le.fit_transform(test_df['Province_State'])
",32
288,"from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df_train.Country_Region = le.fit_transform(df_train.Country_Region)
df_train['Province_State'] = le.fit_transform(df_train['Province_State'])
df_test.Country_Region = le.fit_transform(df_test.Country_Region)
df_test['Province_State'] = le.fit_transform(df_test['Province_State'])
",32
289,"from datetime import timedelta
TEST_DAYS = 7
TRAIN_LAST =  - timedelta(days=TEST_DAYS)
TEST_FIRST = sub_df[""Date""].min()
TEST_DAYS = (df[""Date""].max() - TEST_FIRST).days + 1
dev_df, test_df = df[df[""Date""] < TEST_FIRST].copy(), df[df[""Date""] >= TEST_FIRST].copy()
dev_df.shape, test_df.shape
",32
290,"world = train.groupby('Date')['ConfirmedCases', 'Fatalities'].sum().reset_index()
plt.plot(world['Date'], world['ConfirmedCases'], label = 'Confirmed Cases')
plt.plot(world['Date'], world['Fatalities'], label = 'Fatalities')
plt.legend()
plt.title('Total number of Confirmed Cases and Fatalities Worldwide')
plt.xticks(rotation = 30)
plt.show();
",32
291,"country = train.groupby('Country_Region')['ConfirmedCases', 'Fatalities'].sum().reset_index()
fig = plt.figure(figsize = (15, 25))
ax = fig.add_subplot(111)
ax.barh(country['Country_Region'], country['ConfirmedCases'],label = 'Confirmed Cases')
ax.barh(country['Country_Region'], country['Fatalities'],label = 'Fatalities')
ax.legend()
ax.set_title('Total Confirmed Cases and Fatalities by Country');
",32
292,"case_scaler = MinMaxScaler(feature_range=(0, 100))
fat_scaler = MinMaxScaler(feature_range=(0, 100))
train_data['ConfirmedCases_scaled'] = case_scaler.fit_transform(train_data['ConfirmedCases'].values.reshape(-1,1))
train_data['Fatalities_scaled'] = fat_scaler.fit_transform(train_data['Fatalities'].values.reshape(-1,1))
",32
293,"dftrain =  pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/train.csv"")
dftrain[""GrowthRate""] = dftrain[""ConfirmedCases""] / dftrain.ConfirmedCases.shift(1)
print(dftrain.Date.unique())
dftest = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/test.csv"")
print(dftest.columns.values)
dfsubmission  = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/submission.csv"")
",32
294,"train[""City Group""] = train[""City Group""].map({""Big Cities"": 0, ""Other"":1})
test[""City Group""] = test[""City Group""].map({""Big Cities"": 0, ""Other"":1})
train[""Type""] = train[""Type""].map({""FC"": 0, ""IL"":1,""DT"":2})
test[""Type""] = test[""Type""].map({""FC"": 0, ""IL"":1,""DT"":2})
",32
295,"groups_dict =dfg.groups
for group, indexes in groups_dict.items():
    print(group)
    tempdf = df.loc[indexes[0]:indexes[-1]]
    print(tempdf.shape)
    if False:
        tempdf[""Growth""] = tempdf.ConfirmedCases/tempdf.ConfirmedCases.shift(1)
        tempdf[""FGrowth""] = tempdf.Fatalities/tempdf.Fatalities.shift(1)
        tempdf.plot(""Date"", [""Growth"",""FGrowth""])
",32
296,"fig,ax = plt.subplots(figsize=(8,5))
for i in highest_cases_countries.index:
    _=ax.plot(regions[regions['Country_Region']==i]['Date'],
             regions[regions['Country_Region']==i]['ConfirmedCases'],label=i)
    _=ax.legend()
    _=ax.xaxis.set_tick_params(rotation=15)
    _=sns.despine()
    _=ax.set(title='Regions with highest cases')
",32
297,"X_train_cc = X_train_cc.reshape(X_train_cc.shape[0], 1, X_train_cc.shape[1])
X_val_cc = X_val_cc.reshape(X_val_cc.shape[0], 1, X_val_cc.shape[1])
X_train_ft = X_train_ft.reshape(X_train_ft.shape[0], 1, X_train_ft.shape[1])
X_val_ft = X_val_ft.reshape(X_val_ft.shape[0], 1, X_val_ft.shape[1])
print(X_train_cc.shape, X_val_cc.shape, X_train_ft.shape, X_val_ft.shape)
",32
298,"SUB_FIRST = sub_df[""Date""].min()
SUB_DAYS = (sub_df[""Date""].max() - sub_df[""Date""].min()).days + 1
sub_df = dev_df.append(sub_df, sort=False)
for col in TARGETS:
    sub_df[""prev_{}"".format(col)] = sub_df.groupby(loc_group)[col].shift()
sub_df = sub_df[sub_df[""Date""] >= SUB_FIRST].copy()
sub_df[""ForecastId""] = sub_df[""ForecastId""].astype(np.int16)
sub_df = predict(sub_df, SUB_FIRST, SUB_DAYS)
for col in TARGETS:
    sub_df[col] = np.expm1(sub_df[""pred_{}"".format(col)])
sub_df.head()
",32
299,"RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)
",33
300,"RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)
",33
301,"for f2 in [""Region""]:
    me2 = MeanEncoding(f2, C=0.01 * len(X2[f2].unique()))
    me2.fit(X2, y2)
    X2 = me2.transform(X2)
    test_2 = me2.transform(test_2)
",33
302,"for f1 in [""Region""]:
    me1 = MeanEncoding(f1, C=0.01 * len(X1[f1].unique()))
    me1.fit(X1, y1)
    X1 = me1.transform(X1)
    test_1 = me1.transform(test_1)
",33
303,"print(train['Date'].max())
print(test['Date'].min())
print(test['Date'].max())
",33
304,"print('Validate if train and test is splited correctly for 2 cases: ')
print('cumulative cases training has shape ', X_train_cc.shape, y_train_cc.shape)
print('fatal cases training has shape ', X_train_ft.shape, y_train_ft.shape)
print('cumulative cases valid has shape ', X_val_cc.shape, y_val_cc.shape)
print('fatal cases valid has shape ', X_val_ft.shape, y_val_ft.shape)
print('Validate if train and test contains np.nan, np.inf, -np.inf after standardization: ')
",33
305,"regressor = KerasRegressor(build_fn = build_regressor,verbose=0)
parameters = {'lstm_nodes':[14,16,20],
             'nb_epoch':[50],
             'batch_size':[32],
             'optimizer':['adam']}
gridsearch = GridSearchCV(estimator = regressor,
                 param_grid = parameters,
                 scoring = 'neg_mean_squared_log_error',
                 cv = 10,
                 n_jobs = -1,
                 verbose =0)
",33
306,"train['Date'] = pd.to_datetime(train['Date'])
test['Date'] = pd.to_datetime(test['Date'])
",34
307,"xtrain.ConfirmedCases = xtrain.ConfirmedCases.astype('int64')
xtrain.Fatalities = xtrain.Fatalities.astype('int64')
",34
308,"df_out.ForecastId = df_out.ForecastId.astype('int')
df_out2.ForecastId = df_out2.ForecastId.astype('int')
",34