Code_Block,Cluster
"# Plot training & validation loss values
plt.figure(figsize=(8,5))
plt.plot(history_cc.history['loss'])
plt.plot(history_cc.history['val_loss'])
plt.title('CC Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()",0
"# Plot training & validation loss values
plt.figure(figsize=(8,5))
plt.plot(history_ft.history['loss'])
plt.plot(history_ft.history['val_loss'])
plt.title('FT Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()",0
"italy = df_train[df_train['Country_Region'] == 'Italy']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'Fatalities' , data = italy,color='orange')
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Fatalities',size=15)
plt.title('Fatalities in Italy per Date',size=20)
plt.show()",0
"usa = df_train[df_train['Country_Region'] == 'US']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'ConfirmedCases' , data = usa,color='g')
plt.xticks(rotation = 90,size=13)
plt.xlabel('Date',size=15)
plt.ylabel('Confirmed Cases',size=15)
plt.title('Confirmed Cases in US per Date',size=20)
plt.show()",0
"china  = df_train[df_train['Country_Region'] == 'China']

plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'ConfirmedCases' , data = china,color='aqua')
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Confirmed Cases',size=15)
sns.set_context('paper')
plt.title('Confirmed Cases in China per Date',size=20)
plt.show()",0
"china  = df_train[df_train['Country_Region'] == 'China']

plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'Fatalities' , data = china,color='grey')
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Fatalities',size=15)
sns.set_context('paper')
plt.title('Fatalities in China per Date',size=20)
plt.show()",0
"plt.figure(figsize=(20,10))
sns.barplot(x='Province_State',y='ConfirmedCases',data=usa,ci=None)
plt.xticks(rotation = 90,size=13)
plt.xlabel('Province_State',size=15)
plt.ylabel('Confirmed Cases',size=15)
plt.title('Confirmed Cases in US Province_State ',size=20)
plt.show()",0
"plt.figure(figsize=(20,10))
sns.barplot(x='Province_State',y='ConfirmedCases',data=china)
plt.xticks(rotation = 90,size=13)
plt.title('Confirmed Cases in China Province_State',size=20)
plt.ylabel('Confirmed Cases',size=15)
plt.xlabel('Province_State',size=15)
plt.show()",0
"italy = df_train[df_train['Country_Region'] == 'Italy']
plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'ConfirmedCases' , data = italy)
plt.xticks(rotation = 90,size=12)
plt.xlabel('Date',size=15)
plt.ylabel('Confirmed Cases',size=15)
plt.title('Confirmed Cases per date in Italy',size=20)
plt.show()",0
"from sklearn import linear_model
from sklearn.ensemble import RandomForestRegressor

cls = RandomForestRegressor(n_estimators=170)
cls.fit(xTrain, yTrain)
pred = cls.predict(xTest)
pred = numpy.exp(pred)
closs = cls.score(xTrain, yTrain)
closs",0
"idx = np.random.RandomState(seed=42).permutation(train_X_cc.index)
train_X_cc = train_X_cc.reindex(idx)
train_y_cc = train_y_cc.reindex(idx)
train_X_ft = train_X_ft.reindex(idx)
train_y_ft = train_y_ft.reindex(idx)
# train_y_cc.tail()",0
"# if choose to not apply normalization, however it generates NaN in output...
X_train_cc = train_X_cc.to_numpy()  
X_val_cc = val_X_cc.to_numpy()
X_train_ft = train_X_ft.to_numpy()
X_val_ft = val_X_ft.to_numpy()

y_train_cc = train_y_cc.to_numpy()
y_val_cc = val_y_cc.to_numpy()
y_train_ft = train_y_ft.to_numpy()
y_val_ft = val_y_ft.to_numpy()",0
"# Plots
plt.figure(figsize=(12,6))
plt.plot(italy_30)
plt.plot(spain_30)
plt.plot(UK_30)
plt.plot(singapore_30)
plt.legend([""Italy"", ""Spain"", ""UK"", ""Singapore""], loc='upper left')
plt.title(""COVID-19 infections from the first confirmed case"", size=15)
plt.xlabel(""Days"", size=13)
plt.ylabel(""Infected cases"", size=13)
plt.ylim(0, 60000)
plt.show()'",0
"#Regression on everything
from sklearn.ensemble import RandomForestRegressor
import seaborn as sns
import numpy

sns.set_context(""notebook"", font_scale=1.11)
sns.set_style(""ticks"")

yTrain = Train_data['revenue'].apply(numpy.log)
Train_data = Train_data.drop([""revenue""],1)
xTrain = pd.DataFrame(Train_data)
xTest = pd.DataFrame(Test_data)
'",0
"plt.figure(figsize=(20,10))
sns.lineplot(x = 'Date' , y = 'Fatalities' , data = usa,color='purple')
plt.title('Fatalities in US per Date',size=20)
plt.xticks(rotation = 90,size=13)
plt.xlabel('Date',size=15)
plt.ylabel('Fatalities',size=15)
plt.show()",0
"cityPerc = trainData[[""City Group"", ""revenue""]].groupby(['City Group'],as_index=False).mean()
#sns.barplot(x='City Group', y='revenue', data=cityPerc)

citygroupDummy = pd.get_dummies(trainData['City Group'])
trainData = trainData.join(citygroupDummy)

citygroupDummyTest = pd.get_dummies(testData['City Group'])
testData = testData.join(citygroupDummyTest)

trainData = trainData.drop('City Group', axis=1)
testData = testData.drop('City Group', axis=1)'",0
"plt.figure(figsize=(40,40))
temp_df= df_train[df_train['ConfirmedCases']>5000]
sns.barplot(y = temp_df['Country_Region'] , x = temp_df['ConfirmedCases']>10000)
sns.set_context('paper')
plt.ylabel(""Country_Region"",fontsize=30)
plt.xlabel(""Counts"",fontsize=30)
plt.title(""Counts of Countries affected by the pandemic that have confirmed cases > 5000"",fontsize=30)
plt.xticks(rotation = 90)'",0
"# plot global cases and fatalities temporally
global_cases = train_data.groupby(['Date'])[['ConfirmedCases','Fatalities']].sum()

fig,ax = plt.subplots(figsize=(8,5))
_=ax.plot(global_cases['ConfirmedCases'],label='Cases',c='k')
_=ax.plot(global_cases['Fatalities'],label='Deaths',c='r')
_=ax.xaxis.set_tick_params(rotation=15)
_=sns.despine()
_=ax.legend(loc=0)
_=ax.set(title=('Global cumulative cases and deaths'))",0
"fig,ax = plt.subplots(figsize=(8,5))
for i in highest_cases_countries.index:
    _=ax.plot(regions[regions['Country_Region']==i]['Date'],
             regions[regions['Country_Region']==i]['ConfirmedCases'],label=i)
    _=ax.legend()
    _=ax.xaxis.set_tick_params(rotation=15)
    _=sns.despine()
    _=ax.set(title='Regions with highest cases')",0
"train_levels = Train_data.loc[(Train_data['City'].notnull())]
City_counts = train_levels['City'].value_counts().sort_index().to_frame()
City_counts",1
"train_levels = Train_data.loc[(Train_data['Type'].notnull())]
label_counts = train_levels['Type'].value_counts().sort_index().to_frame()
label_counts",1
"# normalization
X_scaler_cc = MinMaxScaler()
X_train_cc = X_scaler_cc.fit_transform(train_X_cc)
X_val_cc =  X_scaler_cc.transform(val_X_cc) # intput/output 2D array-like

y_scaler_cc = MinMaxScaler()
y_train_cc = y_scaler_cc.fit_transform(train_y_cc)
y_val_cc = y_scaler_cc.transform(val_y_cc) # array-like",2
"X_scaler_ft = MinMaxScaler()
X_train_ft = X_scaler_ft.fit_transform(train_X_ft)
X_val_ft =  X_scaler_ft.transform(val_X_ft) # intput/output 2D array-like

y_scaler_ft = MinMaxScaler()
y_train_ft = y_scaler_ft.fit_transform(train_y_ft)
y_val_ft = y_scaler_ft.transform(val_y_ft) # array-like",2
"# Date wise confirm case view in an lineplot
plt.figure(figsize=(15,6))
sns.lineplot(x=xtrain.Date,y=xtrain.ConfirmedCases,markers=True,style=True)
plt.xticks(rotation = 'vertical')",3
"# Date wise Fatalities view in an lineplot
plt.figure(figsize=(15,6))
sns.lineplot(x=xtrain.Date,y=xtrain.Fatalities,markers=True,style=True)
plt.xticks(rotation = 'vertical')",3
"for f2 in [""Region""]:
    me2 = MeanEncoding(f2, C=0.01 * len(X2[f2].unique()))
    me2.fit(X2, y2)
    X2 = me2.transform(X2)
    test_2 = me2.transform(test_2)",4
"for f1 in [""Region""]:
    me1 = MeanEncoding(f1, C=0.01 * len(X1[f1].unique()))
    me1.fit(X1, y1)
    X1 = me1.transform(X1)
    test_1 = me1.transform(test_1)",4
"X_Train.Country = le.fit_transform(X_Train.Country)
X_Train['State'] = le.fit_transform(X_Train['State'])

X_Train.head()",5
"X_Test.Country = le.fit_transform(X_Test.Country)
X_Test['State'] = le.fit_transform(X_Test['State'])

X_Test.head()",5
"
#1.Ridge Regression

#Model import 

from sklearn.linear_model import Ridge

#train classifier
reg_CC = Ridge(alpha=1.0)
reg_Fat = Ridge(alpha=1.0)

#Cross Validation to calculate the score
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)

#rmsle_svm = test_model_r2(clf_svm, ""CC"")

#Print the scores
print (score_CC.mean(), score_Fat.mean())
",6
"
#3. ElasticNet

#Model import 
from sklearn.linear_model import ElasticNet

#train classifier
reg_CC = ElasticNet(random_state=0)
reg_Fat = ElasticNet(random_state=0)

#Cross Validation to calculate the score
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)

#Print the scores
print (score_CC.mean(), score_Fat.mean())
",6
"
#2.Lasso Regression

#Model import 

from sklearn import linear_model

#train classifier
reg_CC = linear_model.Lasso(alpha=0.1)
reg_Fat = linear_model.Lasso(alpha=0.1)

#Cross Validation to calculate the score
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)

#rmsle_svm = test_model_r2(clf_svm, ""CC"")

#Print the scores
print (score_CC.mean(), score_Fat.mean())
",6
"
#5. LinearRegression

#Model import 

from sklearn.linear_model import LinearRegression

#train classifier
reg_CC = LinearRegression()
reg_Fat = LinearRegression()

#Cross Validation to calculate the score
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)

#Print the scores
print (score_CC.mean(), score_Fat.mean())

",7
"
#3. SVM

#Model import 

from sklearn import svm

#train classifier
reg_CC = svm.SVC()
reg_Fat = svm.SVC()

#Cross Validation to calculate the score
score_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)
score_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)

#Print the scores
print (score_CC.mean(), score_Fat.mean())
",7
"
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

train_df.Country_Region = le.fit_transform(train_df.Country_Region)
train_df['Province_State'] = le.fit_transform(train_df['Province_State'])

test_df.Country_Region = le.fit_transform(test_df.Country_Region)
test_df['Province_State'] = le.fit_transform(test_df['Province_State'])
",8
"from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df_train.Country_Region = le.fit_transform(df_train.Country_Region)
df_train['Province_State'] = le.fit_transform(df_train['Province_State'])

df_test.Country_Region = le.fit_transform(df_test.Country_Region)
df_test['Province_State'] = le.fit_transform(df_test['Province_State'])
",8
"from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

X_Train.Country = le.fit_transform(X_Train.Country)
X_Train['State'] = le.fit_transform(X_Train['State'])

X_Test.Country = le.fit_transform(X_Test.Country)
X_Test['State'] = le.fit_transform(X_Test['State'])

print(""*""*50)
print(X_Train.head())
print(""*""*50)
print(X_Test.head())
print(""*""*50)'",8
"train['Date'] = pd.to_datetime(train['Date'])
test['Date'] = pd.to_datetime(test['Date'])
train['Country_Region'] = train['Country_Region'].astype(str)
# train['Province_State'] = train['Province_State'].astype(str)
test['Country_Region'] = test['Country_Region'].astype(str)
# test['Province_State'] = test['Province_State'].astype(str)",8
"#Viewing the total number of confirmeed cases and fatalities worldwide
world = train.groupby('Date')['ConfirmedCases', 'Fatalities'].sum().reset_index()

plt.plot(world['Date'], world['ConfirmedCases'], label = 'Confirmed Cases')
plt.plot(world['Date'], world['Fatalities'], label = 'Fatalities')
plt.legend()
plt.title('Total number of Confirmed Cases and Fatalities Worldwide')
plt.xticks(rotation = 30)
plt.show();",8
"#Plotting the number of confirmed cases and fatalities for each country
country = train.groupby('Country_Region')['ConfirmedCases', 'Fatalities'].sum().reset_index()

fig = plt.figure(figsize = (15, 25))
ax = fig.add_subplot(111)
ax.barh(country['Country_Region'], country['ConfirmedCases'],label = 'Confirmed Cases')
ax.barh(country['Country_Region'], country['Fatalities'],label = 'Fatalities')
ax.legend()
ax.set_title('Total Confirmed Cases and Fatalities by Country');",8
"last_amount = test.loc[(test['Country_Region']=='China')&(test['Province_State']!='Hubei')&(test['Date']=='2020-03-31'),'ConfirmedCases_x']
last_fat = test.loc[(test['Country_Region']=='China')&(test['Province_State']!='Hubei')&(test['Date']=='2020-03-31'),'Fatalities_x']",9
"last_amount = test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']=='2020-03-31'),'ConfirmedCases_x']
last_fat = test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']=='2020-03-31'),'Fatalities_x']",9
"i = 0
k = 30
for date in dates:
    k = k-1
    i = i+1
    test.loc[(test['Country_Region']=='China')&(test['Province_State']!='Hubei')&(test['Date']==date),
             'Fatalities_x']= last_fat.values
    test.loc[(test['Country_Region']=='China')&(test['Province_State']!='Hubei')&(test['Date']==date),
             'ConfirmedCases_x']= last_amount.values + i",9
"k=30
i=0
for date in dates:
    k = k-1
    i = i+1
    test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']==date),'ConfirmedCases_x']= last_amount.values[0]
    test.loc[(test['Country_Region']=='China')&(test['Province_State']=='Hubei')&(test['Date']==date),'Fatalities_x']= last_fat.values[0] + i ",9
"for date in dates:
    k = k-1
    i = i+1
    test.loc[(test['Country_Region']=='Italy')&(test['Date']==date),
            'ConfirmedCases_x']=last_amount.values[0] + i*(5000-(100*i))
    test.loc[(test['Country_Region']=='Italy')&(test['Date']==date),
             'Fatalities_x'] =  last_fat.values[0]+i*(800-(10*i))",9
"#X_Train = df_train.loc[:, ['State', 'Country', 'Date']]
X_Train = df_train.copy()

X_Train['State'].fillna(EMPTY_VAL, inplace=True)
X_Train['State'] = X_Train.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)

X_Train.loc[:, 'Date'] = X_Train.Date.dt.strftime(""%m%d"")
X_Train[""Date""]  = X_Train[""Date""].astype(int)

X_Train.head()'",10
"#X_Test = df_test.loc[:, ['State', 'Country', 'Date']]
X_Test = df_test.copy()

X_Test['State'].fillna(EMPTY_VAL, inplace=True)
X_Test['State'] = X_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)

X_Test.loc[:, 'Date'] = X_Test.Date.dt.strftime(""%m%d"")
X_Test[""Date""]  = X_Test[""Date""].astype(int)

X_Test.head()'",10
"# CHANGE TO PD.DATETIME
xtrain.Date = pd.to_datetime(xtrain.Date, infer_datetime_format=True)
xtest.Date = pd.to_datetime(xtest.Date, infer_datetime_format=True)",11
"df_train['Date'] = pd.to_datetime(df_train['Date'], infer_datetime_format=True)
df_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)",11
"#Import Date
xtrain = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/train.csv"")
xtest = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/test.csv"")
xsubmission = pd.read_csv(""/kaggle/input/covid19-global-forecasting-week-2/submission.csv"")
# view shape of test and train data
print(xtrain.shape)
print(xtest.shape)",12
"#reading data
data = pd.read_csv('../input/covid19-global-forecasting-week-2/train.csv')
test_data = pd.read_csv('../input/covid19-global-forecasting-week-2/test.csv')
submission = pd.read_csv('../input/covid19-global-forecasting-week-2/submission.csv')
print(data.shape)
print(test_data.shape)
print(submission.shape)",12
"#
def rmsle (y_true, y_pred):
    return np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))'",13
"# customize loss function which is aligned with kaggle evaluation
def root_mean_squared_log_error(y_true, y_pred):
    return K.sqrt(K.mean(K.square(K.log(y_pred + 1) - K.log(y_true + 1)))) ",13
"#metric

def RMSLE(pred,actual):
        return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))",13
"import plotly.express as px
import plotly.graph_objs as go
from plotly.subplots import make_subplots
import plotly
plotly.offline.init_notebook_mode() # For not show up chart error

import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
%matplotlib inline

from tqdm import tqdm

def RMSLE(pred,actual):
    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))",13
"print('Start model training')
start_time = time.time()
history_cc = model_cc.fit(X_train_cc, y_train_cc, epochs = 100,validation_data = (X_val_cc, y_val_cc), verbose = 2, callbacks=[early_stop])
model_cc.save(""model_cc.h5"")
print('Time spent for model training is {} minutes'.format(round((time.time()-start_time)/60,1)))'",14
"print('Start model training')
start_time = time.time()
history_ft = model_ft.fit(X_train_ft, y_train_ft, epochs = 100,validation_data = (X_val_ft, y_val_ft), verbose = 2, callbacks=[early_stop])
model_ft.save(""model_ft.h5"")
print('Time spent for model training is {} minutes'.format(round((time.time()-start_time)/60,1)))'",14
"le = preprocessing.LabelEncoder()
train['province_encoder'] = le.fit_transform(train['Province_State'])
test['province_encoder'] = le.transform(test['Province_State'])",15
"df_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})
soln = pd.DataFrame({'ForecastId': test_df.ForecastId, 'ConfirmedCases': Y_pred_CC, 'Fatalities': Y_pred_Fat})
df_out = pd.concat([df_out, soln], axis=0)
df_out.ForecastId = df_out.ForecastId.astype('int')",15
"RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)",16
"RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)",16
